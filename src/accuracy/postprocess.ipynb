{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "\n",
    "# initial generated sequence from each configuration.,
    "input_files = [\n",
    "    \"answer-vanilla.jsonl\",\n",
    "    \"answer-matkv.jsonl\",\n",
    "    \"answer-matkv-reverse.jsonl\",\n",
    "]\n",
    "\n",
    "for input_file in input_files:\n",
    "    # ì˜ˆ: \"answer-vanilla.jsonl\" -> \"vanilla.jsonl\"\n",
    "    output_file = input_file.replace(\"answer-\", \"\")\n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as fin, \\\n",
    "         open(output_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        for i, line in enumerate(fin):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            data = json.loads(line)\n",
    "\n",
    "            new_data = OrderedDict()\n",
    "            new_data[\"id\"] = i\n",
    "\n",
    "            for k, v in data.items():\n",
    "                if k != \"id\":\n",
    "                    new_data[k] = v\n",
    "\n",
    "            fout.write(json.dumps(new_data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "input_files = [\n",
    "    \"vanilla.jsonl\",\n",
    "    \"matkv.jsonl\",\n",
    "    \"matkv-reverse.jsonl\"\n",
    "]\n",
    "\n",
    "for input_file in input_files:\n",
    "    output_file = os.path.splitext(input_file)[0] + \"-final.jsonl\"\n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as fin, \\\n",
    "         open(output_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            data = json.loads(line)\n",
    "            answer = data.get(\"answer\", \"\")\n",
    "\n",
    "            idx = answer.find(\"\\n\\n\")\n",
    "            if idx != -1:\n",
    "                answer = answer[:idx]\n",
    "\n",
    "            data[\"answer\"] = answer.strip()\n",
    "\n",
    "            fout.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunwooshin/openai-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation for vanilla-final.jsonl ===\n",
      "ROUGE Scores (Average F-measure):\n",
      "ROUGE-1: 0.2481\n",
      "ROUGE-2: 0.1062\n",
      "ROUGE-L: 0.2438\n",
      "\n",
      "BERTScore (Average):\n",
      "Precision: 0.4446\n",
      "Recall   : 0.5667\n",
      "F1       : 0.4882\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation for matkv-final.jsonl ===\n",
      "ROUGE Scores (Average F-measure):\n",
      "ROUGE-1: 0.2688\n",
      "ROUGE-2: 0.1089\n",
      "ROUGE-L: 0.2643\n",
      "\n",
      "BERTScore (Average):\n",
      "Precision: 0.4729\n",
      "Recall   : 0.5822\n",
      "F1       : 0.5118\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "=== Evaluation for matkv-reverse-final.jsonl ===\n",
      "ROUGE Scores (Average F-measure):\n",
      "ROUGE-1: 0.2480\n",
      "ROUGE-2: 0.1048\n",
      "ROUGE-L: 0.2441\n",
      "\n",
      "BERTScore (Average):\n",
      "Precision: 0.4764\n",
      "Recall   : 0.5703\n",
      "F1       : 0.5090\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "\n",
    "# 1) Load JSONL files\n",
    "references = []\n",
    "with open('answer.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        references.append(json.loads(line.strip()))\n",
    "\n",
    "ref_dict = {item[\"id\"]: item[\"answer\"] for item in references}\n",
    "\n",
    "# List of generated JSONL filenames\n",
    "generated_files = [\n",
    "    \"vanilla-final.jsonl\",\n",
    "    \"matkv-final.jsonl\",   # add more files as needed\n",
    "    \"matkv-reverse-final.jsonl\"\n",
    "]\n",
    "\n",
    "# Iterate over each generated file and compute metrics\n",
    "for gen_file in generated_files:\n",
    "    generated = []\n",
    "    with open(gen_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            generated.append(json.loads(line.strip()))\n",
    "\n",
    "    # Create a mapping for generated responses: id -> answer\n",
    "    gen_dict = {item[\"id\"]: item[\"answer\"] for item in generated}\n",
    "\n",
    "    # Get the list of common IDs\n",
    "    common_ids = sorted(list(set(ref_dict.keys()) & set(gen_dict.keys())))\n",
    "    ref_texts = [ref_dict[i] for i in common_ids]\n",
    "    gen_texts = [gen_dict[i] for i in common_ids]\n",
    "\n",
    "    # 2) ROUGE Evaluation\n",
    "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = [rouge.score(ref, gen) for ref, gen in zip(ref_texts, gen_texts)]\n",
    "    \n",
    "    avg_rouge1_f = sum(s['rouge1'].fmeasure for s in rouge_scores) / len(rouge_scores)\n",
    "    avg_rouge2_f = sum(s['rouge2'].fmeasure for s in rouge_scores) / len(rouge_scores)\n",
    "    avg_rougeL_f = sum(s['rougeL'].fmeasure for s in rouge_scores) / len(rouge_scores)\n",
    "\n",
    "    # 3) BERTScore Evaluation\n",
    "    # You can change model_type if needed (e.g., \"roberta-base\")\n",
    "    P, R, F1 = score(gen_texts, ref_texts, model_type=\"bert-base-uncased\")\n",
    "    avg_precision = P.mean().item()\n",
    "    avg_recall = R.mean().item()\n",
    "    avg_f1 = F1.mean().item()\n",
    "\n",
    "    # Output the evaluation for the current file\n",
    "    print(f\"=== Evaluation for {gen_file} ===\")\n",
    "    print(\"ROUGE Scores (Average F-measure):\")\n",
    "    print(f\"ROUGE-1: {avg_rouge1_f:.4f}\")\n",
    "    print(f\"ROUGE-2: {avg_rouge2_f:.4f}\")\n",
    "    print(f\"ROUGE-L: {avg_rougeL_f:.4f}\\n\")\n",
    "\n",
    "    print(\"BERTScore (Average):\")\n",
    "    print(f\"Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Recall   : {avg_recall:.4f}\")\n",
    "    print(f\"F1       : {avg_f1:.4f}\")\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
